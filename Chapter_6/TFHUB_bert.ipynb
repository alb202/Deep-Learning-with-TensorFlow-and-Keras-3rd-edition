{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": ["import seaborn as sns\nfrom sklearn.metrics import pairwise\n\nimport tensorflow as tf\nimport tensorflow_hub as hub\nimport tensorflow_text as text  # Imports TF ops for preprocessing.\n\nsentences = [\n\t\"Do not pity the dead, Harry. Pity the living, and, above all those who live without love.\",\n\t\"It is impossible to manufacture or imitate love\",\n\t\"Differences of habit and language are nothing at all if our aims are identical and our hearts are open.\",\n\t\"What do I care how he looks? I am good-looking enough for both of us, I theenk! All these scars show is zat my husband is brave!\",\n\t\"Love as powerful as your mother\u00e2\u20ac\u2122s for you leaves it\u00e2\u20ac\u2122s own mark. To have been loved so deeply, even though the person who loved us is gone, will give us some protection forever.\",\n\t\"Family\u00e2\u20ac\u00a6Whatever yeh say, blood\u00e2\u20ac\u2122s important. . . .\",\n\t\"I cared more for your happiness than your knowing the truth, more for your peace of mind than my plan, more for your life than the lives that might be lost if the plan failed.\"\n]\n\n\n#@title Configure the model { run: \"auto\" }\nBERT_MODEL = \"https://tfhub.dev/google/experts/bert/wiki_books/2\" # @param {type: \"string\"} [\"https://tfhub.dev/google/experts/bert/wiki_books/2\", \"https://tfhub.dev/google/experts/bert/wiki_books/mnli/2\", \"https://tfhub.dev/google/experts/bert/wiki_books/qnli/2\", \"https://tfhub.dev/google/experts/bert/wiki_books/qqp/2\", \"https://tfhub.dev/google/experts/bert/wiki_books/squad2/2\", \"https://tfhub.dev/google/experts/bert/wiki_books/sst2/2\",  \"https://tfhub.dev/google/experts/bert/pubmed/2\", \"https://tfhub.dev/google/experts/bert/pubmed/squad2/2\"]\n# Preprocessing must match the model, but all the above use the same.\nPREPROCESS_MODEL = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"\n\npreprocess = hub.load(PREPROCESS_MODEL)\nbert = hub.load(BERT_MODEL)\ninputs = preprocess(sentences)\noutputs = bert(inputs)\n\nprint(\"Sentences:\")\nprint(sentences)\n\nprint(\"\\nBERT inputs:\")\nprint(inputs)\n\nprint(\"\\nPooled embeddings:\")\nprint(outputs[\"pooled_output\"])\n\nprint(\"\\nPer token embeddings:\")\nprint(outputs[\"sequence_output\"])\n\n\ndef plot_similarity(features, labels):\n  \"\"\"Plot a similarity matrix of the embeddings.\"\"\"\n  cos_sim = pairwise.cosine_similarity(features)\n  sns.set(font_scale=1.2)\n  cbar_kws=dict(use_gridspec=False, location=\"left\")\n  g = sns.heatmap(\n      cos_sim, xticklabels=labels, yticklabels=labels,\n      vmin=0, vmax=1, cmap=\"Blues\", cbar_kws=cbar_kws)\n  g.tick_params(labelright=True, labelleft=False)\n  g.set_yticklabels(labels, rotation=0)\n  g.set_title(\"Semantic Textual Similarity\")\n\nplot_similarity(outputs[\"pooled_output\"], sentences)"]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}